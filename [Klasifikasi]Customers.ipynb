{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Import Library**"
      ],
      "metadata": {
        "id": "fKADPWcFKlj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ],
      "metadata": {
        "id": "LgA3ERnVn84N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import randint\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ],
      "metadata": {
        "id": "f3YIEnAFKrKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ],
      "metadata": {
        "id": "Ey3ItwTen_7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Memuat dataset hasil clustering\n",
        "df = pd.read_csv('Clustered_Customers.csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "GHCGNTyrM5fS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc3075f-cc82-4359-ebc5-b5e545a7591d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   CustomerID  Gender  Age  Annual Income ($)  Spending Score (1-100)  \\\n",
            "0           1    Male   19            15000.0                      39   \n",
            "1           2    Male   21            35000.0                      81   \n",
            "2           3  Female   20            86000.0                       6   \n",
            "3           4  Female   23            59000.0                      77   \n",
            "4           5  Female   31            38000.0                      40   \n",
            "\n",
            "      Profession  Work Experience  Family Size  Cluster  \n",
            "0     Healthcare                1            4        2  \n",
            "1       Engineer                3            3        2  \n",
            "2       Engineer                1            1        1  \n",
            "3         Lawyer                0            2        2  \n",
            "4  Entertainment                2            6        2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Splitting**"
      ],
      "metadata": {
        "id": "KkPem5eWL2UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ],
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pisahkan fitur (X) dan target (y)\n",
        "X = df.drop(columns=['Cluster', 'CustomerID'])\n",
        "y = df['Cluster']"
      ],
      "metadata": {
        "id": "OubAW-7ONKVj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding data categorical\n",
        "categorical_cols = ['Gender', 'Profession']\n",
        "numerical_cols = X.columns.difference(categorical_cols)\n",
        "\n",
        "# Membuat pipeline untuk jika terdapat menangani missing values, encoding, dan scaling\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='mean')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numerical_cols),\n",
        "        ('cat', Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', OneHotEncoder())\n",
        "        ]), categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Menggunakan pipeline preprocessor\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Membagi data menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "2cU_kcLFk60a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ],
      "metadata": {
        "id": "IVPbB03CMhTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ],
      "metadata": {
        "id": "Ned1pL9zMmBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ],
      "metadata": {
        "id": "WAWzPOE4Nkti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mengatasi ketidakseimbangan data dengan SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Mengurangi dimensi dengan PCA (jaga 95% variansi)\n",
        "pca = PCA(n_components=0.95)\n",
        "X_train_resampled = pca.fit_transform(X_train_resampled)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "# Parameter distribusi untuk Random Forest\n",
        "rf_param_dist = {\n",
        "    'n_estimators': randint(50, 150),\n",
        "    'max_depth': randint(5, 20),\n",
        "    'min_samples_split': randint(4, 10),\n",
        "    'min_samples_leaf': randint(2, 5),\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV untuk Random Forest dengan cv=10\n",
        "rf_random_search = RandomizedSearchCV(RandomForestClassifier(random_state=42), rf_param_dist, n_iter=10, cv=10,\n",
        "                                      scoring='f1_weighted', n_jobs=-1, random_state=42)\n",
        "rf_random_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Menampilkan hyperparameter terbaik untuk Random Forest\n",
        "print(\"Best parameters for Random Forest:\", rf_random_search.best_params_)\n",
        "\n",
        "# Model terbaik dari RandomizedSearchCV\n",
        "rf_best_model = rf_random_search.best_estimator_\n",
        "\n",
        "# Evaluasi model pada data testing\n",
        "rf_y_pred = rf_best_model.predict(X_test)"
      ],
      "metadata": {
        "id": "4JYxBe87NLDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a343f2ab-5212-46c9-fd66-e10ca69747dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Random Forest: {'bootstrap': False, 'max_depth': 19, 'min_samples_leaf': 3, 'min_samples_split': 9, 'n_estimators': 96}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis narasi atau penjelasan algoritma yang Anda gunakan."
      ],
      "metadata": {
        "id": "seYoHNY3XU1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ergzChZFEL-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ],
      "metadata": {
        "id": "zOm68u-7NpLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi hasil model Random Forest\n",
        "print(\"\\nRandom Forest Classification Report:\")\n",
        "print(classification_report(y_test, rf_y_pred))\n",
        "\n",
        "rf_f1 = f1_score(y_test, rf_y_pred, average='weighted')\n",
        "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
        "print(f\"Random Forest F1-score: {rf_f1:.2f}\")\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "tMq4QAssNLip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19eae533-bff4-4c63-9e4e-11c1ddf5a6a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       212\n",
            "           1       0.92      0.85      0.88       217\n",
            "           2       0.86      0.93      0.90       161\n",
            "\n",
            "    accuracy                           0.92       590\n",
            "   macro avg       0.91      0.92      0.92       590\n",
            "weighted avg       0.92      0.92      0.92       590\n",
            "\n",
            "Random Forest F1-score: 0.92\n",
            "Random Forest Accuracy: 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan cross-validation\n",
        "cv_scores = cross_val_score(rf_best_model, X_train_resampled, y_train_resampled, cv=5, scoring='f1_weighted')\n",
        "\n",
        "# Menampilkan skor rata-rata cross-validation\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean Cross-Validation Score:\", cv_scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS_SGckUl6Al",
        "outputId": "42079663-1978-405c-ba23-c4f03d033761"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.89564305 0.91932953 0.88848044 0.90628635 0.89362792]\n",
            "Mean Cross-Validation Score: 0.9006734580551395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya."
      ],
      "metadata": {
        "id": "H4_9OwrsXZlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
        "2. Identifikasi kelemahan model, seperti:\n",
        "  - Precision atau Recall rendah untuk kelas tertentu.\n",
        "  - Apakah model mengalami overfitting atau underfitting?\n",
        "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan."
      ],
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Precision atau Recall Rendah untuk Kelas Tertentu\n",
        "\n",
        "Berdasarkan **classification report** yang saya dapatkan, terlihat bahwa **precision** dan **recall** untuk masing-masing kelas memiliki perbedaan yang signifikan:\n",
        "\n",
        "- **Kelas 0** (Precision: 0.96, Recall: 0.98): Hasilnya cukup memuaskan karena memiliki precision dan recall yang sangat baik.\n",
        "- **Kelas 1** (Precision: 0.92, Recall: 0.85): Recall di sini agak rendah dibandingkan precision, yang berarti model agak kesulitan untuk mengenali kelas ini dengan baik.\n",
        "- **Kelas 2** (Precision: 0.86, Recall: 0.93): Meskipun recall cukup tinggi, precision agak rendah, yang menunjukkan model cukup baik dalam mendeteksi kelas ini tetapi sering memberikan prediksi positif yang salah.\n",
        "\n",
        "Saya merasa bahwa masalah utama ada pada kelas 1, di mana recall lebih rendah daripada precision, yang mungkin disebabkan oleh ketidakseimbangan data yang belum sepenuhnya terselesaikan meskipun saya sudah menggunakan **SMOTE** untuk menangani masalah ini.\n",
        "\n",
        "\n",
        "\n",
        "# 2. Apakah Model Mengalami Overfitting atau Underfitting?\n",
        "\n",
        "Dari hasil **cross-validation scores** yang saya peroleh, dengan rata-rata sekitar 0.90, model saya tampaknya cukup stabil. F1-score antara data training dan testing tidak terlalu berbeda jauh, yang menunjukkan bahwa model ini bisa menggeneralisasi dengan baik. Ini berarti model tidak menunjukkan tanda-tanda **overfitting** atau **underfitting** yang jelas.\n",
        "\n",
        "Namun, saya tetap perlu waspada terhadap **overfitting** jika ada kesenjangan besar antara performa di data training dan testing, atau jika model terlalu kompleks karena banyaknya hyperparameter yang dioptimalkan. Untuk lebih meyakinkan, saya bisa mencoba melihat **learning curve** atau menggunakan teknik regulasi lain seperti **dropout** atau **penalti**.\n",
        "\n",
        "\n",
        "\n",
        "# 3. Rekomendasi Tindakan Lanjutan\n",
        "\n",
        "- **Mengatasi Ketidakseimbangan Data**: Walaupun saya sudah menggunakan SMOTE, saya merasa ketidakseimbangan data masih menjadi masalah. Beberapa langkah yang bisa saya coba adalah:\n",
        "  - Meningkatkan **tuning SMOTE** untuk mendapatkan sampel yang lebih seimbang dan mengurangi potensi overfitting pada kelas minoritas.\n",
        "  - Menerapkan **penalti pada kelas minoritas** (misalnya, dengan menggunakan parameter `class_weight` di Random Forest) untuk memberikan bobot lebih pada kelas yang kurang terwakili.\n",
        "\n",
        "- **Pengumpulan Data Tambahan**: Jika kelas tertentu, seperti kelas 1, masih menunjukkan performa yang buruk, saya pikir pengumpulan data lebih banyak untuk kelas tersebut dapat sangat membantu untuk meningkatkan akurasi model.\n",
        "\n",
        "- **Cobalah Algoritma Lain**: Walaupun Random Forest cukup baik, saya berpikir ada kemungkinan algoritma lain bisa memberikan hasil yang lebih baik:\n",
        "  - **XGBoost** atau **LightGBM**, yang lebih kuat dalam menangani ketidakseimbangan data dan sering memberikan hasil yang lebih baik pada dataset dengan noise.\n",
        "  - **SVM** dengan **kernel non-linear** juga bisa menjadi pilihan jika model lain lebih cocok untuk dataset ini.\n",
        "\n",
        "- **Pengoptimalan Hyperparameter**: Saya sudah mencoba **RandomizedSearchCV**, tetapi saya bisa memperbanyak iterasi atau mencoba teknik lain seperti **Bayesian optimization** untuk menemukan parameter yang lebih optimal.\n",
        "\n"
      ],
      "metadata": {
        "id": "nRsoa1Msmurs"
      }
    }
  ]
}